{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Pandas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Read data file\n",
    "**pd.read_csv('file_path', delimiter=',', skiprows=n, header=m, index_col=k)**  \n",
    "- Specify the file path as the first argument.\n",
    "- Specify the delimiter with the delimiter argument. It can be omitted if the delimiter is a comma (,).\n",
    "If the delimiter is a tab: ‘\\t’, if it is blank: ‘\\s+’  \n",
    "You may use sep argument instead of delimiter argument  \n",
    "- Specify the number of rows to skip in the skiprows argument. Can be omitted if there is no line to skip.    \n",
    "- Specify the column label with the header argument. None if there is no column label.  \n",
    "- Specify the row label with the index_col argument. Omit it if there is no row level.\n",
    "\n",
    "※ Check the contents of the file before reading the data file  \n",
    "Right-click the data file you want to open in JupyterLab, Open With > Editor  \n",
    "\n",
    "(Note) In Pandas, the data type may be different for each column. (In NumPy, all elements have the same data type)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('data/user_data1.csv',delimiter=',')\n",
    "display(df.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In the following explanation, let df be a DataFrame variable. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Condition extraction of DataFrame\n",
    "\n",
    "**df[condition]**  \n",
    "Example of how to write a condition  \n",
    "- `df[df[\"col_name\"] == value1]` Extract rows where the specified column value matches the value1. \n",
    "- `df[df[\"col_name\"] > value2]` Extract rows where the specified column value is greater than the value2   \n",
    "\n",
    "Specifying multiple conditions:   \n",
    "- AND(&): df[(cond_1)&(cond_2)]  \n",
    "- OR(|): df[(cond_1)|(cond_2)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "display(df[df[\"age\"] > 50]) # Show over 50 years old"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "display(df[(df[\"gender\"] == \"M\")&(df[\"age\"] < 30 )]) # Show male and under 30 years old"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Add row to DataFrame\n",
    "\n",
    "**pd.concat([df, ser.to_frame().T],ignore_index=True)**\n",
    "\n",
    "- Make the index of the row to be added the same as the column label of the DataFrame\n",
    "- An index is automatically assigned with the argument `ignore_index = True`\n",
    "- Series is converted to a 2-d Dataframe using to_frame(). Since it yields a column, so transpose it with \".T\" to make it to a row.\n",
    "-　Seriesをto_frame()を用いて２次元のDataFrameに変換する。さらに、そのままでは列になっているので、「.T」を用いて転置をし、行にする。\n",
    "- Combine the new dataframe with the dataframe using pd.concat."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert the row to be added to Series and make the column label the same as DataFrame\n",
    "ser = pd.Series([1013,20,\"M\",\"student\"],index=df.columns) \n",
    "print(ser)\n",
    "print(df.columns)\n",
    "\n",
    "df2 = pd.concat([df, ser.to_frame().T],ignore_index=True)\n",
    "display(df2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Add column to DataFrame\n",
    "\n",
    "**df[\"new_col\"] = list or Series**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add a new column \"year\" to represent the year of birth\n",
    "df[\"year\"] = 2020 - df[\"age\"]\n",
    "display(df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Delete rows / columns of DataFrame\n",
    "\n",
    "Delete columns:  \n",
    "**df.drop(columns=\"col_name\")**  or  **df.drop(\"col_name\",axis=1)**\n",
    "\n",
    "Delete rows:  \n",
    "**df.drop(index=row_num)**  or  **df.drop(row_num)**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.drop(columns=\"year\")\n",
    "display(df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Merge DataFrame\n",
    "\n",
    "How to combine two DataFrames with common columns into one DataFrame.  \n",
    "The common columns considered in the merge is called \"key\".\n",
    "\n",
    "**pd.merge(df1,df2,on=\"col_name\",how=\"types_of_merge\")**\n",
    "\n",
    "- The DataFrame of the first argument is the table on the left, and the DataFrame of the second argument is the table on the right.\n",
    "- on: Column or index level names to join on. These must be found in both DataFrames.   \n",
    "- how: Type of merge to be performed.\n",
    "```\n",
    "how=\"inner\": inner join. Extract and merge only the common rows of the keys of the two DataFrames\n",
    "how=\"outer\": outer join. Merge using all rows in two DataFrames\n",
    "how=\"left\": use only keys from left frame\n",
    "how=\"right\": use only keys from right frame\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df2 = pd.read_csv('data/user_data2.csv',delimiter=',')\n",
    "display(df2.head())\n",
    "\n",
    "# The common column is \"id\". Merge by outer join.\n",
    "df_new = pd.merge(df,df2,on=\"id\",how=\"outer\")\n",
    "display(df_new)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Group DataFrame\n",
    "\n",
    "Data can be aggregated for each category group and the total, maximum, minimum, average, etc. can be calculated.\n",
    "\n",
    "**df.groupby(\"col_name\").statistic_function**\n",
    "\n",
    "Statistical functions are sum(), max(), min(), mean(), etc."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Aggregate data for each occupation and calculate the average value of each column (numerical data column only)\n",
    "df.groupby(\"occupation\").mean()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Sort\n",
    "\n",
    "**df.sort_values(by=[\"col_name1\"],ascending=True)**  \n",
    "\n",
    "In the argument `ascending`, specify True for ascending order and False for descending order for each corresponding column.  \n",
    "\n",
    "Sort by multiple columns:  \n",
    "**df.sort_values(by=[\"col1\",\"col2\"],ascending=[True,True])**  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "display(df_new.sort_values(by=[\"age\"],ascending=True))# Sort by age"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Write to CSV file\n",
    "\n",
    "**df.to_csv('file_path')**\n",
    "\n",
    "When the argument `header = False` is added, does not write out the column names.    \n",
    "When the argument `index=False` is added, does not wtite row names (index).   \n",
    "When the argument `columns=[\"col1, col2\"]` is added, only the specified columns can be written."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_new.to_csv('data/new_user_data.csv')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
